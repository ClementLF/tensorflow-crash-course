{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cudnngru_fmnist.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dEV4mdrFirhq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fashion-MNIST\n",
        "\n",
        "\n",
        "RNN worflow based on the work of [Aymeric Damien](https://github.com/aymericdamien/TensorFlow-Examples/) and [Sungjoon](https://github.com/sjchoi86/tensorflow-101/blob/master/notebooks/rnn_mnist_simple.ipynb)\n",
        "\n",
        "Good resource: [How to use Dataset in TensorFlow](https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428)"
      ]
    },
    {
      "metadata": {
        "id": "dHHh1RgEirhs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN Overview\n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" alt=\"nn\" style=\"width: 600px;\"/>\n",
        "\n",
        "References:\n",
        "- [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf), Sepp Hochreiter & Jurgen Schmidhuber, Neural Computation 9(8): 1735-1780, 1997."
      ]
    },
    {
      "metadata": {
        "id": "Rpw14qsZjRrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## System Information"
      ]
    },
    {
      "metadata": {
        "id": "-_6tSle2jRFw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "2555618b-acec-4361-b91b-d86d84729496",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522656706262,
          "user_tz": -480,
          "elapsed": 4694,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install watermark"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: watermark in /usr/local/lib/python3.6/dist-packages\r\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from watermark)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->watermark)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/lib/python3/dist-packages (from ipython->watermark)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->watermark)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->watermark)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->watermark)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eKF1CsFIjX-y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3c6b3d7e-7424-4f89-f169-33c08003afa6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522656709094,
          "user_tz": -480,
          "elapsed": 1364,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%load_ext watermark\n",
        "%watermark -v -m -p tensorflow,numpy -g"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The watermark extension is already loaded. To reload it, use:\n",
            "  %reload_ext watermark\n",
            "CPython 3.6.3\n",
            "IPython 5.5.0\n",
            "\n",
            "tensorflow 1.6.0\n",
            "numpy 1.14.2\n",
            "\n",
            "compiler   : GCC 7.2.0\n",
            "system     : Linux\n",
            "release    : 4.4.111+\n",
            "machine    : x86_64\n",
            "processor  : x86_64\n",
            "CPU cores  : 2\n",
            "interpreter: 64bit\n",
            "Git hash   :\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CoMaBW7cjZeC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "80ddcdda-4b4a-4480-c1bd-7ccda9a08fdf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522656719664,
          "user_tz": -480,
          "elapsed": 10340,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# From https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn't guaranteed\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages\n",
            "Gen RAM Free: 9.0 GB  I Proc size: 4.2 GB\n",
            "GPU RAM Free: 9678MB | Used: 1761MB | Util  15% | Total 11439MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "USWNEwU0jbea",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import random \n",
        "from datetime import datetime\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib import rnn\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gp3aDETqouXK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "4d491a99-2a06-49b5-e448-91eb0d1300c3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522656723358,
          "user_tz": -480,
          "elapsed": 2302,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr  2 08:12:02 2018       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n",
            "| N/A   37C    P0    61W / 149W |   1761MiB / 11439MiB |      0%      Default |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                       GPU Memory |\r\n",
            "|  GPU       PID   Type   Process name                             Usage      |\r\n",
            "|=============================================================================|\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WI-Yvpy8sLFw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "ab270d29-2952-442c-fbc5-ab49a61085b3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522656725714,
          "user_tz": -480,
          "elapsed": 2332,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ps -ef|grep python"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root        90    80  0 00:11 ?        00:00:14 /usr/bin/python /usr/local/bin/jupyter-notebook -y --no-browser --log-level=DEBUG --debug --NotebookApp.allow_origin=\"*\" --NotebookApp.log_format=\"%(message)s\" --NotebookApp.token= --Session.key=\"\" --Session.keyfile=\"\" --ContentsManager.untitled_directory=\"Untitled Folder\" --ContentsManager.untitled_file=\"Untitled File\" --ContentsManager.untitled_notebook=\"Untitled Notebook\" --NotebookNotary.algorithm=\"sha1\" --KernelManager.autorestart=True --MultiKernelManager.default_kernel_name=\"python2\" --ip=\"127.0.0.1\" --port=9000 --port-retries=0 --notebook-dir=\"/content\" --NotebookNotary.algorithm=sha256 --NotebookNotary.secret_file=/content/datalab/.config/notary_secret --NotebookApp.base_url=/tun/m/gpu-50aa25b0-cff1-4d08-a893-3da31a333462/\r\n",
            "root      1134    90 55 04:49 ?        01:53:23 /usr/bin/python3 -m ipykernel_launcher -f /content/.local/share/jupyter/runtime/kernel-51cd6d5d-2d4d-43a6-8cd5-a7e22403b5f3.json\r\n",
            "root      1202    90  0 04:50 ?        00:00:02 /usr/bin/python3 -m ipykernel_launcher -f /content/.local/share/jupyter/runtime/kernel-50854c92-c04b-465e-b2d2-a6e076a7a541.json\r\n",
            "root      1658  1134 99 08:12 pts/0    00:00:01 /bin/sh -c ps -ef|grep python\r\n",
            "root      1660  1658  0 08:12 pts/0    00:00:00 grep python\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j8ez3SK6irh4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare Fashon-MNIST\n",
        "[Data Source](https://www.kaggle.com/zalando-research/fashionmnist/data)"
      ]
    },
    {
      "metadata": {
        "id": "p2YmeISTnR8g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2247cda-6215-4e14-bc32-b8f50e7bbaac",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522656731824,
          "user_tz": -480,
          "elapsed": 3684,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'personal-project-196600 '\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v5nt0QJYnR_g",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "5bef6e0a-eb16-4b5e-91a5-04de6c981492",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522656742192,
          "user_tz": -480,
          "elapsed": 10334,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Download the file from a given Google Cloud Storage bucket.\n",
        "!gsutil cp gs://colab-tmp/fashion-mnist_train.csv .\n",
        "!gsutil cp gs://colab-tmp/fashion-mnist_test.csv ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://colab-tmp/fashion-mnist_train.csv...\n",
            "| [1 files][126.9 MiB/126.9 MiB]                                                \n",
            "Operation completed over 1 objects/126.9 MiB.                                    \n",
            "Copying gs://colab-tmp/fashion-mnist_test.csv...\n",
            "- [1 files][ 21.2 MiB/ 21.2 MiB]                                                \n",
            "Operation completed over 1 objects/21.2 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QE-ptuiwirh6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc178511-c5cf-49b8-ffcc-fd9960c3a695",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522656752118,
          "user_tz": -480,
          "elapsed": 9886,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"fashion-mnist_train.csv\")\n",
        "df_test = pd.read_csv(\"fashion-mnist_test.csv\")\n",
        "print(df_train.shape, df_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 785) (10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3ji7Up9Xirh-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "6d0c2cc1-af61-498d-d0af-0e862327800d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522656753320,
          "user_tz": -480,
          "elapsed": 1164,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(df_train.columns)\n",
        "print(df_test.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['label', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
            "       'pixel7', 'pixel8', 'pixel9',\n",
            "       ...\n",
            "       'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n",
            "       'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n",
            "      dtype='object', length=785)\n",
            "Index(['label', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
            "       'pixel7', 'pixel8', 'pixel9',\n",
            "       ...\n",
            "       'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n",
            "       'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n",
            "      dtype='object', length=785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K6U05J7tiriE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "424e8bb4-5d23-488b-8a2b-6af021e12c6c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522656754610,
          "user_tz": -480,
          "elapsed": 1086,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Train/Validation Split\n",
        "idx = np.arange(60000)\n",
        "np.random.shuffle(idx)\n",
        "print(idx[:5])\n",
        "df_val = df_train.iloc[idx[:10000]]\n",
        "df_train = df_train.iloc[idx[10000:]]\n",
        "print(df_val.shape, df_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[31325 57677 37900 23176 38365]\n",
            "(10000, 785) (50000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fPAXvPGNiriK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the Model"
      ]
    },
    {
      "metadata": {
        "id": "XfIhYkiqiriM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b1b4b12-d68e-4bb6-f5af-a471a49fbf1c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522662857302,
          "user_tz": -480,
          "elapsed": 1166,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.002\n",
        "training_steps = 10000\n",
        "batch_size = 32\n",
        "display_step = 500\n",
        "print(\"Total batches per epoch:\", np.ceil(df_train.shape[0] / batch_size))\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 1 # MNIST data input (img shape: 28*28)\n",
        "timesteps = 28 * 28 # timesteps\n",
        "num_hidden = 128 # hidden layer num of features\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total batches per epoch: 1563.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YJU_PVQfiriS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def RNN(x):\n",
        "    # Define a lstm cell with tensorflow\n",
        "    gru = tf.contrib.cudnn_rnn.CudnnGRU(\n",
        "            1, num_hidden,\n",
        "            # kernel_initializer=tf.random_normal_initializer(0, 1))\n",
        "            kernel_initializer=tf.orthogonal_initializer())\n",
        "            # kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=True))\n",
        "            # kernel_initializer=tf.truncated_normal_initializer())\n",
        "\n",
        "    # Get lstm cell output\n",
        "    # outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
        "    outputs, _ = gru(tf.transpose(x, (1, 0, 2)))\n",
        "    # return tf.matmul(outputs[-1, :, :], weights['out']) + biases['out']\n",
        "    output_layer = tf.layers.Dense(\n",
        "        num_classes, activation=None, \n",
        "        # kernel_initializer=tf.random_normal_initializer(0, 1),\n",
        "        kernel_initializer=tf.orthogonal_initializer(),\n",
        "        # kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=True),\n",
        "        # kernel_initializer=tf.glorot_uniform_initializer(),\n",
        "        trainable=True\n",
        "    )\n",
        "    # Linear activation, using rnn inner loop last output\n",
        "    return output_layer(tf.layers.batch_normalization(outputs[-1, :, :]))\n",
        "    # return output_layer(outputs[-1, :, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w7V_3E7-iriU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def process_batch(batch_x, batch_y):\n",
        "    return tf.expand_dims(batch_x, -1), tf.one_hot(batch_y, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZZUBNLlHiric",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "    tf.set_random_seed(10)\n",
        "    \n",
        "    with tf.variable_scope(\"datasets\"):\n",
        "        training_batch_size = tf.placeholder(tf.int64) # tf.constant(32, dtype=\"int64\")\n",
        "        inference_batch_size = tf.placeholder(tf.int64) # tf.constant(500, dtype=\"int64\")\n",
        "\n",
        "        fminst_ds_train = tf.data.Dataset.from_tensor_slices(\n",
        "            (df_train.iloc[:, 1:].astype(\"float32\") / 255, df_train.iloc[:, 0].astype(\"int32\"))\n",
        "        ).shuffle(50000, reshuffle_each_iteration=True).repeat().batch(training_batch_size).map(process_batch)\n",
        "        fminst_ds_val = tf.data.Dataset.from_tensor_slices(\n",
        "            (df_val.iloc[:, 1:].astype(\"float32\") / 255, df_val.iloc[:, 0].astype(\"int32\"))\n",
        "        ).repeat().batch(inference_batch_size).map(process_batch)\n",
        "        fminst_ds_test = tf.data.Dataset.from_tensor_slices((\n",
        "            df_test.iloc[:, 1:].astype(\"float32\") / 255, df_test.iloc[:, 0].astype(\"int32\"))\n",
        "        ).repeat().batch(inference_batch_size).map(process_batch)\n",
        "\n",
        "        handle = tf.placeholder(tf.string, shape=[])\n",
        "        iterator = tf.data.Iterator.from_string_handle(\n",
        "            handle, fminst_ds_train.output_types, fminst_ds_train.output_shapes)\n",
        "\n",
        "        train_iterator = fminst_ds_train.make_initializable_iterator()\n",
        "        val_iterator = fminst_ds_val.make_initializable_iterator()\n",
        "        test_iterator = fminst_ds_test.make_initializable_iterator() \n",
        "    \n",
        "    X_0, Y = iterator.get_next()\n",
        "    X = tf.reshape(X_0, (-1, timesteps, num_input))\n",
        "\n",
        "    # Define weights\n",
        "    logits = RNN(X)\n",
        "    prediction = tf.nn.softmax(logits)\n",
        "   \n",
        "    with tf.name_scope(\"loss\"):\n",
        "        # Define loss and optimizer\n",
        "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "            logits=logits, labels=Y))\n",
        "        ema_loss = tf.get_variable(\"ema_loss\", shape=[], dtype=tf.float32, trainable=False, initializer=tf.constant_initializer(2.5))\n",
        "        ema_update = ema_loss.assign(ema_loss * 0.99 + loss * 0.01)\n",
        "    tf.summary.scalar('Loss', ema_loss)\n",
        "    \n",
        "    with tf.variable_scope(\"optimizer\"):\n",
        "        # optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.1)\n",
        "        gvs = optimizer.compute_gradients(loss)\n",
        "        capped_gvs = [(tf.clip_by_norm(grad, 1.), var) for grad, var in gvs]\n",
        "        with tf.control_dependencies([ema_update]):\n",
        "            train_op = optimizer.apply_gradients(capped_gvs)    \n",
        "        # train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "    with tf.variable_scope(\"inference\"):\n",
        "        # Evaluate model (with test logits, for dropout to be disabled)\n",
        "        correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    with tf.variable_scope('summarize_gradients'):\n",
        "        for grad, var in gvs:\n",
        "            norm = tf.norm(tf.clip_by_norm(grad, 10.), ord=2)\n",
        "            tf.summary.histogram(var.name.replace(\":\", \"_\") + '/gradient_l2', \n",
        "                                 tf.where(tf.is_nan(norm), tf.zeros_like(norm), norm))\n",
        "        for grad, var in capped_gvs:\n",
        "            norm = tf.norm(grad, ord=2)\n",
        "            tf.summary.histogram(var.name.replace(\":\", \"_\") + '/gradient_clipped_l2', \n",
        "                                 tf.where(tf.is_nan(norm), tf.zeros_like(norm), norm)) \n",
        "            \n",
        "    # Initialize the variables (i.e. assign their default value)\n",
        "    init = tf.global_variables_initializer()\n",
        "    saver = tf.train.Saver()\n",
        "    merged_summary_op = tf.summary.merge_all()\n",
        "    # print([x.get_shape() for x in tf.global_variables()])\n",
        "    # print([x.get_shape() for x in tf.trainable_variables()])\n",
        "    # print(\"All parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.global_variables()]))\n",
        "    # print(\"Trainable parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.trainable_variables()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8XUWWBHKirig",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training and Evaluating"
      ]
    },
    {
      "metadata": {
        "id": "f6Bbqx7Eirig",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e8f8daae-f0eb-40a0-9ab0-285c5aa86118"
      },
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "best_val_acc = 0.8\n",
        "\n",
        "train_writer = tf.summary.FileWriter(\"logs/fminst_gru/%s/train\" % datetime.now().strftime(\"%Y%m%d_%H%M\"), graph)\n",
        "val_writer = tf.summary.FileWriter(\"logs/fminst_gru/%s/val\" % datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
        "\n",
        "with tf.Session(graph=graph, config=config) as sess:\n",
        "    sess.run(init) \n",
        "    sess.run([train_iterator.initializer, val_iterator.initializer, test_iterator.initializer],\n",
        "             feed_dict={training_batch_size: batch_size, inference_batch_size: 500})\n",
        "    train_handle, val_handle, test_handle = sess.run(\n",
        "        [train_iterator.string_handle(), val_iterator.string_handle(), test_iterator.string_handle()])\n",
        "    # Run the initializer\n",
        "    for step in range(1, training_steps+1):\n",
        "        sess.run([train_op], feed_dict={handle: train_handle})\n",
        "        \n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss_local, acc, summary = sess.run([loss, accuracy, merged_summary_op], feed_dict={handle: train_handle})\n",
        "            train_writer.add_summary(summary, global_step=step)\n",
        "            train_writer.flush()            \n",
        "            val_acc, val_loss = [], []\n",
        "            for _ in range(20):\n",
        "                tmp = sess.run([accuracy, loss], feed_dict={handle: val_handle})\n",
        "                val_acc.append(tmp[0])\n",
        "                val_loss.append(tmp[1])\n",
        "            summary = tf.Summary()\n",
        "            val_loss = np.mean(val_loss)            \n",
        "            val_acc = np.mean(val_acc)            \n",
        "            summary.value.add(tag='Loss', simple_value=val_loss)\n",
        "            val_writer.add_summary(summary, global_step=step)\n",
        "            val_writer.flush() \n",
        "            print(\"Step \" + str(step) + \", Train Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss_local) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc) + \", Val Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(val_acc))\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
        "                print(\"Model saved in path: %s\" % save_path)  \n",
        "    test_acc = []\n",
        "    for _ in range(20):\n",
        "        test_acc.append(sess.run(accuracy, feed_dict={handle: test_handle}))\n",
        "    test_acc = np.mean(test_acc)\n",
        "    print(\"Test Accuracy= {:.3f}\".format(test_acc))                \n",
        "    print(\"Optimization Finished!\")\n",
        "    \n",
        "train_writer.close()\n",
        "val_writer.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, Train Loss= 2.3047, Training Accuracy= 0.125, Val Accuracy= 0.118\n",
            "Step 500, Train Loss= 1.3528, Training Accuracy= 0.469, Val Accuracy= 0.469\n",
            "Step 1000, Train Loss= 1.1724, Training Accuracy= 0.594, Val Accuracy= 0.497\n",
            "Step 1500, Train Loss= 0.6783, Training Accuracy= 0.781, Val Accuracy= 0.720\n",
            "Step 2000, Train Loss= 0.2735, Training Accuracy= 0.969, Val Accuracy= 0.778\n",
            "Step 2500, Train Loss= 0.3495, Training Accuracy= 0.875, Val Accuracy= 0.798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0RyqWC-4irim",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1e84dff2-c352-456d-9d55-be7faf03a705",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522664320088,
          "user_tz": -480,
          "elapsed": 3190,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session(graph=graph, config=config) as sess:\n",
        "    saver.restore(sess, '/tmp/model.ckpt')\n",
        "    sess.run(test_iterator.initializer,\n",
        "             feed_dict={inference_batch_size: 500})\n",
        "    test_handle = sess.run(test_iterator.string_handle())    \n",
        "    test_acc = []\n",
        "    for _ in range(20):\n",
        "        test_acc.append(sess.run(accuracy, feed_dict={handle: test_handle}))\n",
        "    test_acc = np.mean(test_acc)\n",
        "    print(\"Test Accuracy= {:.3f}\".format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "Test Accuracy= 0.887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ifosj1yYiriq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Permute"
      ]
    },
    {
      "metadata": {
        "id": "awZPUv1eiris",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "training_steps = 15000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dex64oFBiriu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "    tf.set_random_seed(10)\n",
        "    \n",
        "    with tf.variable_scope(\"datasets\"):\n",
        "        training_batch_size = tf.placeholder(tf.int64) # tf.constant(32, dtype=\"int64\")\n",
        "        inference_batch_size = tf.placeholder(tf.int64) # tf.constant(500, dtype=\"int64\")\n",
        "\n",
        "        fminst_ds_train = tf.data.Dataset.from_tensor_slices(\n",
        "            (df_train.iloc[:, 1:].astype(\"float32\") / 255, df_train.iloc[:, 0].astype(\"int32\"))\n",
        "        ).shuffle(50000, reshuffle_each_iteration=True).repeat().batch(training_batch_size).map(process_batch)\n",
        "        fminst_ds_val = tf.data.Dataset.from_tensor_slices(\n",
        "            (df_val.iloc[:, 1:].astype(\"float32\") / 255, df_val.iloc[:, 0].astype(\"int32\"))\n",
        "        ).repeat().batch(inference_batch_size).map(process_batch)\n",
        "        fminst_ds_test = tf.data.Dataset.from_tensor_slices((\n",
        "            df_test.iloc[:, 1:].astype(\"float32\") / 255, df_test.iloc[:, 0].astype(\"int32\"))\n",
        "        ).repeat().batch(inference_batch_size).map(process_batch)\n",
        "\n",
        "        handle = tf.placeholder(tf.string, shape=[])\n",
        "        iterator = tf.data.Iterator.from_string_handle(\n",
        "            handle, fminst_ds_train.output_types, fminst_ds_train.output_shapes)\n",
        "\n",
        "        train_iterator = fminst_ds_train.make_initializable_iterator()\n",
        "        val_iterator = fminst_ds_val.make_initializable_iterator()\n",
        "        test_iterator = fminst_ds_test.make_initializable_iterator() \n",
        "    \n",
        "    X_0, Y = iterator.get_next()\n",
        "    \n",
        "    # Permute the time step\n",
        "    np.random.seed(100)\n",
        "    permute = np.random.permutation(784)\n",
        "    X = tf.gather(\n",
        "        tf.reshape(X_0, (-1, timesteps, num_input)), \n",
        "        permute, axis=1)\n",
        "    \n",
        "    # Define weights\n",
        "    logits = RNN(X)\n",
        "    prediction = tf.nn.softmax(logits)\n",
        "   \n",
        "    with tf.name_scope(\"loss\"):\n",
        "        # Define loss and optimizer\n",
        "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "            logits=logits, labels=Y))\n",
        "        ema_loss = tf.get_variable(\"ema_loss\", shape=[], dtype=tf.float32, trainable=False, initializer=tf.constant_initializer(2.5))\n",
        "        ema_update = ema_loss.assign(ema_loss * 0.99 + loss * 0.01)\n",
        "    tf.summary.scalar('Loss', ema_loss)\n",
        "    \n",
        "    with tf.variable_scope(\"optimizer\"):\n",
        "        # optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
        "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.1)\n",
        "        gvs = optimizer.compute_gradients(loss)\n",
        "        capped_gvs = [(tf.clip_by_norm(grad, 1.), var) for grad, var in gvs]\n",
        "        with tf.control_dependencies([ema_update]):\n",
        "            train_op = optimizer.apply_gradients(capped_gvs)    \n",
        "        # train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "    with tf.variable_scope(\"inference\"):\n",
        "        # Evaluate model (with test logits, for dropout to be disabled)\n",
        "        correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    with tf.variable_scope('summarize_gradients'):\n",
        "        for grad, var in gvs:\n",
        "            norm = tf.norm(tf.clip_by_norm(grad, 10.), ord=2)\n",
        "            tf.summary.histogram(var.name.replace(\":\", \"_\") + '/gradient_l2', \n",
        "                                 tf.where(tf.is_nan(norm), tf.zeros_like(norm), norm))\n",
        "        for grad, var in capped_gvs:\n",
        "            norm = tf.norm(grad, ord=2)\n",
        "            tf.summary.histogram(var.name.replace(\":\", \"_\") + '/gradient_clipped_l2', \n",
        "                                 tf.where(tf.is_nan(norm), tf.zeros_like(norm), norm)) \n",
        "            \n",
        "    # Initialize the variables (i.e. assign their default value)\n",
        "    init = tf.global_variables_initializer()\n",
        "    saver = tf.train.Saver()\n",
        "    merged_summary_op = tf.summary.merge_all()\n",
        "    # print([x.get_shape() for x in tf.global_variables()])\n",
        "    # print([x.get_shape() for x in tf.trainable_variables()])\n",
        "    # print(\"All parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.global_variables()]))\n",
        "    # print(\"Trainable parameters:\", np.sum([np.product([xi.value for xi in x.get_shape()]) for x in tf.trainable_variables()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IDkzgrwXiriy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "bcf5112c-9b1c-4b0f-d189-19c474cfa5e9"
      },
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "best_val_acc = 0.8\n",
        "\n",
        "train_writer = tf.summary.FileWriter(\"logs/fminst_gru/%s/train\" % datetime.now().strftime(\"%Y%m%d_%H%M\"), graph)\n",
        "val_writer = tf.summary.FileWriter(\"logs/fminst_gru/%s/val\" % datetime.now().strftime(\"%Y%m%d_%H%M\"))\n",
        "\n",
        "with tf.Session(graph=graph, config=config) as sess:\n",
        "    sess.run(init) \n",
        "    sess.run([train_iterator.initializer, val_iterator.initializer, test_iterator.initializer],\n",
        "             feed_dict={training_batch_size: batch_size, inference_batch_size: 500})\n",
        "    train_handle, val_handle, test_handle = sess.run(\n",
        "        [train_iterator.string_handle(), val_iterator.string_handle(), test_iterator.string_handle()])\n",
        "    # Run the initializer\n",
        "    for step in range(1, training_steps+1):\n",
        "        sess.run([train_op], feed_dict={handle: train_handle})\n",
        "        \n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss_local, acc, summary = sess.run([loss, accuracy, merged_summary_op], feed_dict={handle: train_handle})\n",
        "            train_writer.add_summary(summary, global_step=step)\n",
        "            train_writer.flush()            \n",
        "            val_acc, val_loss = [], []\n",
        "            for _ in range(20):\n",
        "                tmp = sess.run([accuracy, loss], feed_dict={handle: val_handle})\n",
        "                val_acc.append(tmp[0])\n",
        "                val_loss.append(tmp[1])\n",
        "            summary = tf.Summary()\n",
        "            val_loss = np.mean(val_loss)            \n",
        "            val_acc = np.mean(val_acc)            \n",
        "            summary.value.add(tag='Loss', simple_value=val_loss)\n",
        "            val_writer.add_summary(summary, global_step=step)\n",
        "            val_writer.flush() \n",
        "            print(\"Step \" + str(step) + \", Train Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss_local) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc) + \", Val Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(val_acc))\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
        "                print(\"Model saved in path: %s\" % save_path)  \n",
        "    test_acc = []\n",
        "    for _ in range(20):\n",
        "        test_acc.append(sess.run(accuracy, feed_dict={handle: test_handle}))\n",
        "    test_acc = np.mean(test_acc)\n",
        "    print(\"Test Accuracy= {:.3f}\".format(test_acc))                \n",
        "    print(\"Optimization Finished!\")\n",
        "    \n",
        "train_writer.close()\n",
        "val_writer.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, Train Loss= 2.3060, Training Accuracy= 0.031, Val Accuracy= 0.088\n",
            "Step 500, Train Loss= 1.2360, Training Accuracy= 0.594, Val Accuracy= 0.592\n",
            "Step 1000, Train Loss= 1.0488, Training Accuracy= 0.688, Val Accuracy= 0.669\n",
            "Step 1500, Train Loss= 0.6931, Training Accuracy= 0.750, Val Accuracy= 0.717\n",
            "Step 2000, Train Loss= 0.5201, Training Accuracy= 0.844, Val Accuracy= 0.755\n",
            "Step 2500, Train Loss= 0.4615, Training Accuracy= 0.906, Val Accuracy= 0.768\n",
            "Step 3000, Train Loss= 0.4192, Training Accuracy= 0.844, Val Accuracy= 0.772\n",
            "Step 3500, Train Loss= 0.7379, Training Accuracy= 0.750, Val Accuracy= 0.781\n",
            "Step 4000, Train Loss= 0.3400, Training Accuracy= 0.875, Val Accuracy= 0.789\n",
            "Step 4500, Train Loss= 0.3499, Training Accuracy= 0.906, Val Accuracy= 0.800\n",
            "Model saved in path: /tmp/model.ckpt\n",
            "Step 5000, Train Loss= 0.6448, Training Accuracy= 0.781, Val Accuracy= 0.800\n",
            "Model saved in path: /tmp/model.ckpt\n",
            "Step 5500, Train Loss= 0.5430, Training Accuracy= 0.781, Val Accuracy= 0.797\n",
            "Step 6000, Train Loss= 0.3704, Training Accuracy= 0.812, Val Accuracy= 0.801\n",
            "Model saved in path: /tmp/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c003cJAJiri2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "19de92f9-bc9e-42c9-d79e-5195afc0de01",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1522662751700,
          "user_tz": -480,
          "elapsed": 5020,
          "user": {
            "displayName": "CeShine Lee",
            "photoUrl": "//lh6.googleusercontent.com/-TKaCzeGtBXw/AAAAAAAAAAI/AAAAAAAAjB4/Xqwbek0CNps/s50-c-k-no/photo.jpg",
            "userId": "114938319508229761672"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with tf.Session(graph=graph, config=config) as sess:\n",
        "    saver.restore(sess, '/tmp/model.ckpt')\n",
        "    sess.run(test_iterator.initializer,\n",
        "             feed_dict={inference_batch_size: 500})\n",
        "    test_handle = sess.run(test_iterator.string_handle())    \n",
        "    test_acc = []\n",
        "    for _ in range(20):\n",
        "        test_acc.append(sess.run(accuracy, feed_dict={handle: test_handle}))\n",
        "    test_acc = np.mean(test_acc)\n",
        "    print(\"Test Accuracy= {:.3f}\".format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "Test Accuracy= 0.850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "roARZHuWiri8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}